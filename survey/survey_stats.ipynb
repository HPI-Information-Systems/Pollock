{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import clevercsv\n",
    "import urllib\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "colors = [\"teal\",\"xkcd:tangerine\"]\n",
    "mpl.rc('font',family='Rasa')\n",
    "BAR_WIDTH = 0.3\n",
    "FONT_SIZE = 20\n",
    "TITLE_SIZE = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_from_folder(folder, normalize=True, subset = None):\n",
    "    rows_list = []\n",
    "        \n",
    "    for file in os.listdir(folder+\"annotations/\")[:subset]:\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(folder+\"annotations/\"+file) as ann:\n",
    "                data = json.load(ann)\n",
    "\n",
    "            with open(folder+\"csv/\"+data[\"file_name\"], \"rb\") as csvfile:\n",
    "                data[\"content\"] = csvfile.read()\n",
    "            dialect_folder = f\"./dialects/\"\n",
    "\n",
    "            try:\n",
    "                dialect_file = dialect_folder + data[\"file_name\"]+\"_dialect.json\"\n",
    "                if not os.path.exists(dialect_file):\n",
    "                    dialect_file = dialect_file.replace(\" \", \"%20\")\n",
    "\n",
    "                with open(dialect_file, \"r\") as jf:\n",
    "                    dialect = json.load(jf)[\"dialect\"]\n",
    "            except Exception as e:\n",
    "                print(\"Filename\", dialect_file,e)\n",
    "                if not (data[\"table_not_comma_delimiter\"] or data[\"table_not_double_quote\"] or data[\"table_not_escape_quote\"]):\n",
    "                    dialect[\"delimiter\"] =\",\"\n",
    "                    dialect[\"quotechar\"] = '\"'\n",
    "                    dialect[\"escapechar\"] = '\"'\n",
    "                else:\n",
    "                    print(\"Resorting to clevercsv\")\n",
    "                    with open(folder+\"csv/\"+data[\"file_name\"], \"r\") as csvfile:\n",
    "                        d = clevercsv.Sniffer().sniff(csvfile.read())\n",
    "                    dialect = {\"delimiter\": d.delimiter, \"quotechar\": d.quotechar,\n",
    "                    \"escapechar\": d.escapechar}\n",
    "\n",
    "            data[\"delimiter\"] = dialect[\"delimiter\"]\n",
    "            data[\"quotechar\"] = dialect[\"quotechar\"]\n",
    "            data[\"escapechar\"] = dialect[\"escapechar\"]\n",
    "\n",
    "            rows_list += [data]\n",
    "\n",
    "    df = pd.DataFrame(rows_list)\n",
    "    df[\"encoding_nonascii\"] = (~(df[\"encoding\"] == \"ascii\")).astype(int)\n",
    "    df[\"dimension_nonstd\"] = (~(df[\"dimension\"].between(1024, 128*1024*1024))).astype(int)             \n",
    "    df[\"table_columns\"] = (df[\"table_columns_less_than_2\"] | df[\"table_columns_more_256\"]).astype(int)\n",
    "    df[\"table_header\"] = (df[\"table_no_header\"] | df[\"table_multirow_header\"]).astype(int)\n",
    "    df[\"table_lines\"] = (df[\"table_lines_less_2\"] | df[\"table_lines_more_65k\"]).astype(int)\n",
    "    df[\"table_notes\"] = (df[\"table_preamble_rows\"] | df[\"table_footnote_rows\"]).astype(int)\n",
    "    df[\"column_header\"] = (df[\"column_header_unique\"] | df[\"column_header_non_alnum\"] | df[\"column_header_empty\"] | df[\"column_header_long\"]).astype(int)\n",
    "    df[\"column_boundary\"] = (df[\"column_string_boundary\"] | df[\"column_int_boundary\"] | df[\"column_date_boundary\"]).astype(int)\n",
    "\n",
    "    df[\"table_dialect\"] = (df[\"table_not_crlf_delimiter\"]  |\n",
    "                             df[\"table_not_comma_delimiter\"] |      \n",
    "                             df[\"table_not_double_quote\"]    |\n",
    "                             df[\"table_not_escape_quote\"])\n",
    "    df[\"table_structure\"] = (df[\"table_header\"] | df[\"table_lines\"] | df[\"table_columns\"])\n",
    "    \n",
    "    df[\"row_inconsistent_dialect\"] =(df[\"row_inconsistent_record_delimiter\"] |\n",
    "        df[\"row_inconsistent_field_delimiter\"] |\n",
    "        df[\"row_inconsistent_quotation\"] |\n",
    "        df[\"row_inconsistent_escape\"])\n",
    "\n",
    "    df = df.set_index(\"file_name\")\n",
    "    binary = [x for x in df.columns if x not in [\"dimension\", \"encoding\", \"file_name\", \"content\"]]\n",
    "    df[\"non_std\"] = (~df[binary].eq(0).all(axis=1)).astype(int)\n",
    "    binary = [x for x in df.columns if x not in [\"dimension\", \"encoding\", \"file_name\", \"content\"]]\n",
    "    \n",
    "    binary_subset = df[binary]\n",
    "    binary_subset = binary_subset.apply(pd.Series.value_counts).fillna(0)\n",
    "    binary_subset = binary_subset.transpose()\n",
    "    binary_subset = binary_subset.rename(columns={0: \"Standard\", 1: \"Non-standard\"})\n",
    "    if normalize:\n",
    "        binary_subset = binary_subset/len(df)\n",
    "    return df, binary_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SUBSET = None\n",
    "survey_full, survey = get_df_from_folder(\"./\", subset = SUBSET)\n",
    "datasets = list(zip([survey_full], [\"survey\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First rule of our grammar is:\n",
    "\n",
    "```python\n",
    "file = file_payload CRLF{0,1}\n",
    "```\n",
    "\n",
    "We find how many files are empty, have 0, 1 or more than 1 CRLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey\n",
      "\tEmpty files 15 \n",
      "\tNo CRLF 184 \n",
      "\tOne CRLF 3508 \n",
      "\tMore than one CRLF 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_payload = 0\n",
    "zero_files = 0\n",
    "one_files = 0\n",
    "more_files = 0\n",
    "\n",
    "total = False\n",
    "\n",
    "for dataset,name in datasets:\n",
    "    if not total:\n",
    "        no_payload = 0\n",
    "        zero_files = 0\n",
    "        one_files = 0\n",
    "        more_files = 0\n",
    "    for cnt in dataset[\"content\"]:\n",
    "        if cnt !=b'':\n",
    "            if cnt.endswith(b\"\\r\\n\\r\\n\") or cnt.endswith(b\"\\n\\n\") or cnt.endswith(b\"\\r\\r\"):\n",
    "                more_files+=1\n",
    "            elif cnt.endswith(b\"\\r\\n\") or cnt.endswith(b\"\\n\") or cnt.endswith(b\"\\r\"):\n",
    "                one_files+=1\n",
    "            else:\n",
    "                zero_files+=1\n",
    "        else:\n",
    "            no_payload += 1\n",
    "            continue\n",
    "            \n",
    "    if not total:\n",
    "        print(name)\n",
    "        print(\"\\tEmpty files\",no_payload, \"\\n\\tNo CRLF\", zero_files, \"\\n\\tOne CRLF\", one_files,\"\\n\\tMore than one CRLF\", more_files)\n",
    "        print()\n",
    "    \n",
    "if total:\n",
    "    print(\"Total\")\n",
    "    print(\"\\tEmpty files\",no_payload, \"\\n\\tNo CRLF\", zero_files, \"\\n\\tOne CRLF\", one_files,\"\\n\\tMore than one CRLF\", more_files)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second rule states\n",
    "```python\n",
    "file_payload = header{0,1} data\n",
    "```\n",
    "\n",
    "So we sample how many have 0 headers, how many have one, how many have more than one header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey\n",
      "\tNo header 470 \n",
      "\tOne header 2751\n",
      "\tMore than one header 476\n",
      "\t\tPreamble only 282\n",
      "\t\tMore headers only 94\n",
      "\t\tMultitable 232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = False\n",
    "no_header = 0\n",
    "more_header = 0\n",
    "one_header = 0\n",
    "preamble = 0\n",
    "\n",
    "for ds,name in datasets:\n",
    "    dataset = ds[ds[\"content\"]!=b'']\n",
    "    if not total:\n",
    "        no_header = 0\n",
    "        more_header = 0\n",
    "        one_header = 0        \n",
    "        preamble = 0\n",
    "        multitable = 0\n",
    "        multirow = 0\n",
    "        \n",
    "    no_header += len(dataset[dataset[\"table_no_header\"]==1])\n",
    "    preamble += len(dataset[(dataset[\"table_multirow_header\"]==0) & (dataset[\"table_preamble_rows\"]==1)])\n",
    "    multirow += len(dataset[(dataset[\"table_multirow_header\"]==1) & (dataset[\"table_preamble_rows\"] == 0)])\n",
    "    multitable +=len(dataset[dataset[\"table_multiple_tables\"]==1])\n",
    "    \n",
    "    more_header = len(dataset[(dataset[\"table_multirow_header\"]==1) | \n",
    "                              (dataset[\"table_multiple_tables\"]==1) | \n",
    "                              (dataset[\"table_multirow_header\"]==1)])\n",
    "    \n",
    "    one_header += len(dataset) - no_header - more_header\n",
    "    \n",
    "    if not total:\n",
    "        print(name)\n",
    "        print(\"\\tNo header\",no_header, \"\\n\\tOne header\", one_header)\n",
    "        print(\"\\tMore than one header\", more_header)\n",
    "        print(\"\\t\\tPreamble only\", preamble)\n",
    "        print(\"\\t\\tMore headers only\", multirow)\n",
    "        print(\"\\t\\tMultitable\", multitable)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[(dataset[\"table_not_escape_quote\"]==1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The third rule states that \n",
    "```python\n",
    "data= record (CRLF record){0,*}\n",
    "```\n",
    "\n",
    "So we sample how many of the files have no record, a single record, or multiple records.\n",
    "(No record means that it can have a header or be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey\n",
      "\tNo record 3 \n",
      "\tOne record 4 \n",
      "\tMore records 3690\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-dfb788c3d337>:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  no_record = len(dataset[dataset[\"dimension\"]==0][dataset[\"table_lines_less_2\"]==0])\n",
      "<ipython-input-21-dfb788c3d337>:6: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  no_record = len(dataset[dataset[\"dimension\"]==0][dataset[\"table_lines_less_2\"]==0])\n"
     ]
    }
   ],
   "source": [
    "for ds,name in datasets:\n",
    "    dataset = ds[ds[\"content\"]!=b'']\n",
    "    less_than_2_record = len(dataset[dataset[\"table_lines_less_2\"]==1])\n",
    "    more_records = len(dataset[dataset[\"table_lines_less_2\"]==0])\n",
    "    \n",
    "    no_record = len(dataset[dataset[\"dimension\"]==0][dataset[\"table_lines_less_2\"]==0])\n",
    "    one_record= 0\n",
    "    for _,f in dataset[dataset[\"table_lines_less_2\"]==1].iterrows():\n",
    "        if f[\"table_no_header\"]==1:\n",
    "            one_record +=1\n",
    "        else:\n",
    "            no_record +=1\n",
    "            \n",
    "    print(name)\n",
    "    print(\"\\tNo record\",no_record, \"\\n\\tOne record\", one_record, \"\\n\\tMore records\", more_records)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The fourth rule and fifth rule state\n",
    "```python\n",
    "header = field (COMMA field){N,N} CRLF\n",
    "record = field (COMMA field){N,N}\n",
    "```\n",
    "\n",
    "\n",
    "N is a parameter that depends on a given file, so the pollution here is having files where header and records have a different N, or where a record has a different number of fields from other records.\n",
    "We did not find a file where header is not separated with crlf from the rest of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey\n",
      "\tInconsistent N 1040 \n",
      "\tConsistent N 2657\n",
      "\t Multitable 232 \n",
      "\t Preamble 221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO \n",
    "\n",
    "for ds,name in datasets:\n",
    "    dataset = ds[ds[\"content\"]!=b'']\n",
    "    inconsistent_n = len(dataset[dataset[\"row_inconsistent_n_delimiter\"]==1])\n",
    "    inconsistent_n += len(dataset[(dataset[\"table_multiple_tables\"]) & (dataset[\"row_inconsistent_n_delimiter\"]==0)])\n",
    "    multitable = len(dataset[dataset[\"table_multiple_tables\"]==1])\n",
    "    preamble = len(dataset[(dataset[\"table_multiple_tables\"]==0) & ((dataset[\"table_preamble_rows\"]==1) | dataset[\"table_multirow_header\"]==1) & (dataset[\"row_inconsistent_n_delimiter\"]==1)])\n",
    "    consistent_n = len(dataset) - inconsistent_n\n",
    "                \n",
    "    print(name)\n",
    "    print(\"\\tInconsistent N\",inconsistent_n, \"\\n\\tConsistent N\", consistent_n)\n",
    "    print(\"\\t Multitable\", multitable, \"\\n\\t Preamble\", preamble)\n",
    "    print()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last formatting rule states\n",
    "```python\n",
    "escaped = DQUOTE text{0,*} DQUOTE\n",
    "```\n",
    "\n",
    "A pollution to this formatting rule implies that there is an odd number of quotes inside a field:\\\n",
    "If there is no DQUOTE{2} in text:\n",
    "- Either because the first quote or the last quote is missing\\\n",
    "- If both quotes are missing and there is a CR, LF, COMMA, this would be reflected in the previous pollution\n",
    "\n",
    "If there is a DQUOTE{2} in text:\n",
    "- First quote missing means you have an invalid file because you should have delimiter+quote\n",
    "- Second quote missing means you *probably* have a row with an inconsistent number of cells, or a quote never closing\n",
    "- Both quotes missing falls back to invalid file because you should have delimiter-delimiter or delimiter-quote\n",
    "\n",
    "Sanity check: file has an even number of quotes (this assumes that the non-escaped payload rule is respected!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "636it [00:02, 321.27it/s]"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "\n",
    "SUBSET = None\n",
    "\n",
    "for dataset,name in datasets:\n",
    "    non_quoted = 0\n",
    "    correctly_escaped = 0\n",
    "    polluted_escape = 0\n",
    "    non_escaped = 0\n",
    "    cnt_slash = 0\n",
    "    potential_escape = []\n",
    "    for fname,f in tqdm(dataset[:SUBSET].iterrows()):\n",
    "        try:\n",
    "            quotechar = f.quotechar[0] #exclude case where it's quote with space\n",
    "        except IndexError:\n",
    "            quotechar = '\"'\n",
    "        delimiter = f[\"delimiter\"]\n",
    "\n",
    "        x = f[\"content\"]\n",
    "        cnt = 0\n",
    "        rx = re.compile(bytes(f\"^.*{quotechar}.*$\",encoding=\"utf-8\"), re.MULTILINE)\n",
    "        for line in rx.findall(x):\n",
    "            cnt += line.count(bytes(quotechar,encoding=\"utf-8\"))\n",
    "            cnt_slash +=line.count(bytes(f'\\\\{quotechar}', encoding=\"utf-8\"))\n",
    "        if not cnt:\n",
    "            non_quoted += 1\n",
    "            continue\n",
    "\n",
    "        if cnt_slash:\n",
    "            print(\"Found backslash in\", fname)\n",
    "\n",
    "        if cnt%2 != 0: #if there is an odd number they are polluted\n",
    "            polluted_escape+=1\n",
    "            print(\"Polluted escape in:\",fname)\n",
    "            continue\n",
    "\n",
    "        empty_cell = bytes(f\"({delimiter}){quotechar}{quotechar}{delimiter}|^{delimiter}{quotechar}{quotechar}|{delimiter}{quotechar}{quotechar}$\", encoding=\"utf-8\")\n",
    "        rx = re.compile(empty_cell, re.MULTILINE)\n",
    "        x = rx.sub(rb'\\1',x)\n",
    "\n",
    "        rx = re.compile(bytes(f\"^.*{quotechar}{quotechar}.*$\",encoding=\"utf-8\"), re.MULTILINE)\n",
    "        if len(rx.findall(x)):\n",
    "            # print(\"Escaped quote in:\", fname)\n",
    "            potential_escape.append(fname)\n",
    "            correctly_escaped += 1\n",
    "        else:\n",
    "            non_escaped +=1\n",
    "\n",
    "    print(\"\\tPolluted escape\",polluted_escape, \"\\n\\tUnpolluted escape\", correctly_escaped, \"\\n\\tNon escaped\", non_escaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['160930 - Organogram Data - Home Office-senior.csv',\n",
       " '1810IPOpaymentsb.csv',\n",
       " '1901IPOpaymentsb.csv',\n",
       " '1905IPOpaymentsb.csv',\n",
       " '1906IPOpaymentsb.csv',\n",
       " '20130402_gpc_spend_jan13.csv',\n",
       " '2015 thesaurus file.csv',\n",
       " '20150608-foi-cases-received-endmarch-2015.csv',\n",
       " '2015_September_GPC_report.csv',\n",
       " '2016-17_P12_MHRA_GPC_Transparency_Data_-_March_2017.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_escape[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second rule states\n",
    "```python\n",
    "file_payload = header_row{0,1} data\n",
    "```\n",
    "\n",
    "So we sample how many have 0 headers, how many have one, how many have more than one header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second rule states\n",
    "```python\n",
    "file_payload = header_row{0,1} data\n",
    "```\n",
    "\n",
    "So we sample how many have 0 headers, how many have one, how many have more than one header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey\n",
      "\tCRLF 2014\n",
      "\tCR only 7\n",
      "\tLF only 1691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset,name in datasets:\n",
    "    crlf = len(dataset[dataset[\"table_not_crlf_delimiter\"]==0])\n",
    "    only_cr = 0\n",
    "    only_lf = 0        \n",
    "\n",
    "    for idx,f in dataset.iterrows():\n",
    "        if not f[\"table_not_crlf_delimiter\"]:\n",
    "            continue\n",
    "        if f[\"content\"].endswith(b\"\\r\"):\n",
    "            only_cr +=1\n",
    "        elif f[\"content\"].endswith(b\"\\n\"):\n",
    "            only_lf +=1\n",
    "        else:\n",
    "            if re.findall(b\".\\r.\", f[\"content\"], re.MULTILINE):\n",
    "                only_cr +=1\n",
    "            elif re.findall(b\".\\n.\", f[\"content\"], re.MULTILINE):\n",
    "                only_lf +=1\n",
    "            else:\n",
    "                print(f[\"content\"][:1000])\n",
    "\n",
    "    print(name)\n",
    "    print(\"\\tCRLF\",crlf)\n",
    "    print(\"\\tCR only\", only_cr)\n",
    "    print(\"\\tLF only\", only_lf)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey\n",
      "Comma: 2757\n",
      ";      833\n",
      ",       91\n",
      ",\\t     11\n",
      "\\t       5\n",
      "         3\n",
      "Name: delimiter, dtype: int64\n",
      ",    12\n",
      "Name: delimiter, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset,name in datasets:\n",
    "    comma = len(dataset[(dataset[\"table_not_comma_delimiter\"]==0) & (dataset[\"row_inconsistent_field_delimiter\"]==0)])\n",
    "    \n",
    "    print(name)\n",
    "    print(\"Comma:\", comma)\n",
    "    print(dataset[(dataset[\"table_not_comma_delimiter\"]==1)].delimiter.value_counts())\n",
    "    print(dataset[(dataset[\"row_inconsistent_field_delimiter\"]==1)].delimiter.value_counts())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
